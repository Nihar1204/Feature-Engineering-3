{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: What is data encoding? How is it useful in data science?\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# Data encoding is the process of converting data from one format or representation to another.\n",
    "\n",
    "# Uses in Data Science:\n",
    "# Machine Learning Algorithms Require Numerical Input: Most machine learning algorithms are designed to work with \n",
    "# numerical data. They can't directly process text or categorical variables in their original form.   \n",
    "\n",
    "# Enables Pattern Recognition: By encoding categorical data into numerical form, we allow the algorithms to identify \n",
    "# patterns and relationships within the data, which is crucial for tasks like prediction and classification.   \n",
    "\n",
    "# Prevents Bias: Proper encoding helps to ensure that all features (variables) are treated equally by the machine \n",
    "# learning model, preventing bias that might arise from the way categorical data is represented.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. What is nominal encoding? Provide an example of how you would use it in a real-world scenario.\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# Nominal encoding is a type of data encoding used to transform categorical variables where there's no inherent order \n",
    "# or ranking among the categories. The categories are distinct, but one isn't \"better\" or \"higher\" than another.\n",
    "\n",
    "# Example: Customer Preferences\n",
    "\n",
    "# Let's say we're analyzing customer preferences for different types of online content. One of our variables is \n",
    "# \"Content_Type,\" which can have the following categories:\n",
    "\n",
    "# Video\n",
    "# Article\n",
    "# Podcast\n",
    "# Infographic\n",
    "\n",
    "# Since there's no inherent order (one isn't \"better\" than the others), nominal encoding is appropriate. \n",
    "# Here's how one-hot encoding would work:   \n",
    "\n",
    "# Create New Columns: We'd create four new columns, one for each category:  \"Content_Type_Video\", \n",
    "# \"Content_Type_Article\", \"Content_Type_Podcast\", and \"Content_Type_Infographic\".   \n",
    "\n",
    "# Assign Binary Values: For each customer record:\n",
    "\n",
    "# If a customer prefers \"Video\", the \"Content_Type_Video\" column would be 1, and the other three columns would be 0.\n",
    "# If a customer prefers \"Article\", the \"Content_Type_Article\" column would be 1, and the others would be 0.\n",
    "# And so on...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. In what situations is nominal encoding preferred over one-hot encoding? Provide a practical example.\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# 1: High Cardinality Categories: When the categorical column has a large number of unique values, one hot encoding \n",
    "# creates too many new columns, increasing memory usage and reducing model efficiency.\n",
    "# 2: When Ordinal Relationships Exist: If categories have some meaningful relationship or ranking, nominal encoding \n",
    "# (e.g., label encoding or target encoding) helps models learn patterns more effectively.\n",
    "# Tree-Based Models (Decision Trees, Random Forest, XGBoost, etc.): Many tree-based models can naturally handle \n",
    "# label-encoded categorical values without needing one-hot encoding.\n",
    "\n",
    "# Example: Suppose we are working on a fraud detection system for an e-commerce platform, and one of the categorical \n",
    "# features is \"Customer Region\" with 500 unique values (e.g., \"Cuttack\", \"Bhubaneswar\", etc.).\n",
    "\n",
    "# One-Hot Encoding would create 500 new binary columns, making the dataset sparse and computationally expensive.\n",
    "# Nominal Encoding (e.g., Target Encoding) can replace each category with the mean fraud probability in that region, \n",
    "# reducing dimensionality while preserving valuable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. Suppose you have a dataset containing categorical data with 5 unique values. Which encoding technique would you use\n",
    "# to transform this data into a format suitable for machine learning algorithms? Explain why you made this choice.\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# For a dataset containing categorical data with 5 unique values, I would choose One-Hot Encoding (OHE) in most cases.\n",
    "\n",
    "# Why One-Hot Encoding?\n",
    "\n",
    "# 1: Small Number of Categories (Low Cardinality)\n",
    "# Since there are only 5 unique values, one-hot encoding will create only 5 new binary columns, which is manageable and\n",
    "# does not significantly increase dimensionality.\n",
    "\n",
    "# 2: Avoids Implicit Ordinality\n",
    "# If we use Label Encoding (assigning numeric values like {A: 0, B: 1, C: 2, D: 3, E: 4}), machine learning models may \n",
    "# mistakenly interpret the values as ordinal, which is incorrect unless there is a natural ranking.\n",
    "\n",
    "# 3: Works Well with Most ML Models\n",
    "# One-hot encoding is widely supported and effective for models like logistic regression, neural networks, and k-nearest \n",
    "# neighbors, where categorical relationships should not be assumed as numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. In a machine learning project, you have a dataset with 1000 rows and 5 columns. Two of the columns are categorical, \n",
    "# and the remaining three columns are numerical. If you were to use nominal encoding to transform the categorical data, \n",
    "# how many new columns would be created? Show your calculations.\n",
    "\n",
    "# Ans\n",
    "\n",
    "# To determine how many columns will be created, we need to find how many unique values are there in the categorical\n",
    "# columns. For instance column 1 have n and column 2 have m unique values. So after using nominal encoding the total \n",
    "# number of transformed columns would be m+n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. You are working with a dataset containing information about different types of animals, including their species, \n",
    "# habitat, and diet. Which encoding technique would you use to transform the categorical data into a format suitable for \n",
    "# machine learning algorithms? Justify your answer.\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# For a dataset containing categorical information about animals (e.g., species, habitat, and diet), the best encoding \n",
    "# technique depends on the characteristics of each categorical feature.\n",
    "\n",
    "# My choice would be for a hybrid approach.\n",
    "\n",
    "# One-Hot Encoding for column diet because I am assuming it has three values only such as (Herbivore, Carnivore, \n",
    "# Omnivore).\n",
    "# Label Encoding can be used for species, if the dataset contains many unique species names.\n",
    "# Target Encoding can be used for habitat, if the dataset is large and habitat has many unique categories (e.g., Forest, \n",
    "# Desert, Savannah, Ocean, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender  Age  Monthly_Charges  Tenure  Contract_One-Year  Contract_Two-Year\n",
      "0       1   25             70.5       5              False              False\n",
      "1       0   34             50.0      24               True              False\n",
      "2       0   45             90.0      36              False               True\n",
      "3       1   29             65.3      12              False              False\n"
     ]
    }
   ],
   "source": [
    "# Q7.You are working on a project that involves predicting customer churn for a telecommunications company. You have a \n",
    "# dataset with 5 features, including the customer's gender, age, contract type, monthly charges, and tenure. Which \n",
    "# encoding technique(s) would you use to transform the categorical data into numerical data? Provide a step-by-step \n",
    "# explanation of how you would implement the encoding.\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# Step 1: Identify the categorical columns\n",
    "# Given the features:\n",
    "# Gender (Male, Female) → Categorical\n",
    "# Contract Type (Month-to-Month, One-Year, Two-Year) → Categorical\n",
    "# Age, Monthly Charges, and Tenure → Already numerical (No encoding needed)\n",
    "\n",
    "# Step 2: Choosing encoding techniques\n",
    "# Gender (Binary Categorical Feature: 2 unique values). We can use Label Encoding (0/1 Encoding)\n",
    "# Contract Type (Nominal Feature: 3 unique values). We can use One-Hot Encoding.\n",
    "\n",
    "# Step 3: Implementation\n",
    "\n",
    "# Import the packages\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "# Sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'Gender': ['Male', 'Female', 'Female', 'Male'],\n",
    "    'Contract': ['Month-to-Month', 'One-Year', 'Two-Year', 'Month-to-Month'],\n",
    "    'Age': [25, 34, 45, 29],\n",
    "    'Monthly_Charges': [70.5, 50.0, 90.0, 65.3],\n",
    "    'Tenure': [5, 24, 36, 12]\n",
    "})\n",
    "\n",
    "# Step 1: Encode Gender using Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "data['Gender'] = label_encoder.fit_transform(data['Gender'])\n",
    "\n",
    "\n",
    "# Step 2: Encode Contract Type using One-Hot Encoding\n",
    "data = pd.get_dummies(data, columns=['Contract'], drop_first=True)  # Drop first to avoid multicollinearity\n",
    "\n",
    "# Display transformed dataset\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
